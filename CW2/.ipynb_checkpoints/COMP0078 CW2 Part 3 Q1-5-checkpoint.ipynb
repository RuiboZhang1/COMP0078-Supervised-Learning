{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2090ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086c43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for the coursework\n",
    "np.random.seed(124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9763c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the polynomial kernel\n",
    "def polynomial_kernel(p, q, d):\n",
    "    return (p @ q.T) ** d\n",
    "\n",
    "# Define the gaussian kernel\n",
    "def gaussian_kernel(p, q, c):\n",
    "    return np.exp(-c * euclidean_distances(p, q) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5afb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "with open('./dataset/zipcombo.dat', 'r') as file:\n",
    "    for line in file:\n",
    "        values = list(map(float, line.strip().split()))\n",
    "        labels.append(values[0])\n",
    "        images.append(np.array(values[1:]))\n",
    "\n",
    "# images: X, labels: y\n",
    "labels = np.array(labels)\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3d90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the One-vs-the-rest(OvR) Kernel Perceptron\n",
    "class OvRKernelPerceptron:\n",
    "    def __init__(self, epochs, X_train, X_test, y_train, y_test, kernel_type, kernel_param):\n",
    "        self.epochs = epochs  # Number of times the training data will be iterated over\n",
    "        self.X_train = X_train \n",
    "        self.X_test = X_test  \n",
    "        self.y_train = y_train  \n",
    "        self.y_test = y_test  \n",
    "        \n",
    "        # Calculate the number of unique classes in the dataset\n",
    "        self.num_classes = len(np.unique(np.append(y_train, y_test)))\n",
    "        self.train_size = X_train.shape[0]  # Number of training examples\n",
    "        self.test_size = X_test.shape[0]  # Number of testing examples\n",
    "\n",
    "        # Initialise the alpha coefficients for each classifier and training example\n",
    "        self.alpha = np.zeros((self.num_classes, self.train_size))\n",
    "        # Initialise the confusion matrix to record prediction performance\n",
    "        self.confusion_matrix = np.zeros([self.num_classes, self.num_classes])\n",
    "        \n",
    "        # Initialise the kernel based on the specified type and its parameter\n",
    "        if kernel_type == \"polynomial\":\n",
    "            self.K_train = polynomial_kernel(self.X_train, self.X_train, kernel_param)\n",
    "            self.K_test = polynomial_kernel(self.X_test, self.X_train, kernel_param)\n",
    "        elif kernel_type == \"gaussian\":\n",
    "            self.K_train = gaussian_kernel(self.X_train, self.X_train, kernel_param)\n",
    "            self.K_test = gaussian_kernel(self.X_test, self.X_train, kernel_param)\n",
    "        \n",
    "    def predict(self, K_i):\n",
    "        # Make a prediction for the i-th example given its kernel\n",
    "        confidence = self.alpha @ K_i\n",
    "        y_pred = np.argmax(confidence) # The class with the highest confidence will be the prediction\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self):\n",
    "        # Train the perceptron model\n",
    "        errors = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            for t in range(self.train_size):\n",
    "                K_t = self.K_train[t] # Retrieve the kernel for current training example\n",
    "                y_t = int(self.y_train[t])\n",
    "                y_pred = self.predict(K_t)\n",
    "                if y_pred != y_t:\n",
    "                    # Update alpha coefficients for misclassified examples\n",
    "                    self.alpha[y_t, t] += 1\n",
    "                    self.alpha[y_pred, t] -= 1\n",
    "                    errors += 1\n",
    "        # Return the percentage error over all epochs\n",
    "        return errors / (self.epochs * self.train_size) * 100\n",
    "\n",
    "    def test(self):\n",
    "        # Evaluate the model on the test dataset\n",
    "        errors = 0\n",
    "        for i in range(self.test_size):\n",
    "            K_i = self.K_test[i]\n",
    "            y_i = int(self.y_test[i])\n",
    "            y_pred = self.predict(K_i)\n",
    "            if y_i != y_pred:\n",
    "                # Increment error count and update the confusion matrix\n",
    "                errors += 1\n",
    "                self.confusion_matrix[y_i, y_pred] += 1\n",
    "        \n",
    "        # Normalise each row of the confusion matrix\n",
    "        for i in range(self.num_classes):\n",
    "            single_class_count = (self.y_test == i).sum()\n",
    "            self.confusion_matrix[i] = self.confusion_matrix[i] / single_class_count\n",
    "        \n",
    "        # Return the percentage error on the test dataset\n",
    "        return errors / self.test_size * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c603834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(X_train, X_test, y_train, y_test, kernel_type, kernel_param, return_model=False):\n",
    "    # Initialise the perceptron model with specified kernel and kernel parameter\n",
    "    ovr_kernel_perceptron = OvRKernelPerceptron(5, X_train, X_test, y_train, y_test, kernel_type, kernel_param)\n",
    "    \n",
    "    # Train and test model and record their error rates\n",
    "    train_error_rate = ovr_kernel_perceptron.fit()\n",
    "    test_error_rate = ovr_kernel_perceptron.test()\n",
    "    \n",
    "    if return_model: # Return the model when we want to access to the model for further experiments\n",
    "        return ovr_kernel_perceptron, test_error_rate\n",
    "    else:\n",
    "        return train_error_rate, test_error_rate\n",
    "\n",
    "def cross_validate_for_best_parameter(X_train, y_train, kernel_type, param_list, n_splits=5):\n",
    "    # Initialise KFold for cross-validation\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    val_error_rates = np.zeros(len(param_list))\n",
    "\n",
    "    # Loop over each fold in cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        # Create training and validation sets for this fold\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        # Evaluate each parameter using cross-validation\n",
    "        for i, param in enumerate(param_list):\n",
    "            train_error, val_error = train_and_test_model(X_train_fold, X_val_fold, y_train_fold, y_val_fold, kernel_type, param)\n",
    "            val_error_rates[i] += val_error\n",
    "\n",
    "    # Determine the best parameter with minimum validation error rate\n",
    "    best_param = param_list[np.argmin(val_error_rates)]\n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accebc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:14<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 1 \n",
      "    Mean train error rate: 9.969%±0.228%, Mean test error rate: 9.565%±1.872%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:14<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 2 \n",
      "    Mean train error rate: 4.299%±0.106%, Mean test error rate: 4.384%±0.812%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:25<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 3 \n",
      "    Mean train error rate: 2.992%±0.073%, Mean test error rate: 3.801%±0.482%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 4 \n",
      "    Mean train error rate: 2.501%±0.060%, Mean test error rate: 3.204%±0.312%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 5 \n",
      "    Mean train error rate: 2.259%±0.060%, Mean test error rate: 3.285%±0.504%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 6 \n",
      "    Mean train error rate: 2.150%±0.041%, Mean test error rate: 3.258%±0.491%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 7 \n",
      "    Mean train error rate: 2.085%±0.043%, Mean test error rate: 3.239%±0.350%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 3 Q1 \n",
    "\n",
    "# Initialise parameters\n",
    "degree_list = np.arange(1, 8)\n",
    "num_degrees = len(degree_list)\n",
    "num_runs = 20\n",
    "\n",
    "# Initialise arrays to store error rates and stds\n",
    "train_error_rates, test_error_rates = np.zeros(num_degrees), np.zeros(num_degrees)\n",
    "train_stds, test_stds = np.zeros(num_degrees), np.zeros(num_degrees)\n",
    "\n",
    "for degree in degree_list:\n",
    "    degree_train_errors, degree_test_errors = np.zeros(num_runs), np.zeros(num_runs)\n",
    "    \n",
    "    for run in tqdm(range(num_runs)):\n",
    "        # Split into train and test dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)  \n",
    "        \n",
    "        train_error_rate, test_error_rate = train_and_test_model(X_train, X_test, y_train, y_test, 'polynomial', degree)\n",
    "        degree_train_errors[run], degree_test_errors[run] = train_error_rate, test_error_rate\n",
    "\n",
    "    # Print results for current degree\n",
    "    print(f\"Degree: {degree} \\n    Mean train error rate: {degree_train_errors.mean():.3f}%±\\\n",
    "{degree_train_errors.std():.3f}%, Mean test error rate: \\\n",
    "{degree_test_errors.mean():.3f}%±{degree_test_errors.std():.3f}%\")        \n",
    "        \n",
    "    # Store the mean and std of errors for each degree\n",
    "    train_error_rates[degree - 1] = degree_train_errors.mean()\n",
    "    train_stds[degree - 1] = degree_train_errors.std()\n",
    "\n",
    "    test_error_rates[degree - 1] = degree_test_errors.mean()\n",
    "    test_stds[degree - 1] = degree_test_errors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf0a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [09:37<00:00, 28.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test error: 3.269±0.432\n",
      "Mean best degree: 5.600±1.020\n",
      "\n",
      "run: 0, d*=4.0, test error rate=3.871\n",
      "run: 1, d*=6.0, test error rate=3.226\n",
      "run: 2, d*=7.0, test error rate=2.634\n",
      "run: 3, d*=4.0, test error rate=2.796\n",
      "run: 4, d*=5.0, test error rate=2.903\n",
      "run: 5, d*=5.0, test error rate=3.172\n",
      "run: 6, d*=6.0, test error rate=3.280\n",
      "run: 7, d*=7.0, test error rate=3.333\n",
      "run: 8, d*=7.0, test error rate=3.548\n",
      "run: 9, d*=5.0, test error rate=3.226\n",
      "run: 10, d*=5.0, test error rate=3.817\n",
      "run: 11, d*=6.0, test error rate=3.602\n",
      "run: 12, d*=5.0, test error rate=3.925\n",
      "run: 13, d*=7.0, test error rate=3.817\n",
      "run: 14, d*=5.0, test error rate=3.548\n",
      "run: 15, d*=4.0, test error rate=3.011\n",
      "run: 16, d*=5.0, test error rate=3.441\n",
      "run: 17, d*=6.0, test error rate=3.226\n",
      "run: 18, d*=6.0, test error rate=2.419\n",
      "run: 19, d*=7.0, test error rate=2.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Part3 Q2&3\n",
    "\n",
    "# Initialise arrays for storing results\n",
    "num_runs = 20\n",
    "best_degrees = np.zeros(num_runs)\n",
    "test_error_rates = np.zeros(num_runs)\n",
    "\n",
    "# List to store confusion matrices from each run\n",
    "confusion_matrixs = []\n",
    "\n",
    "for run in tqdm(range(num_runs)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "\n",
    "    # Determine and record the best degree of the run from cross-validation\n",
    "    best_degree = cross_validate_for_best_parameter(X_train, y_train, 'polynomial', degree_list)\n",
    "    best_degrees[run] = best_degree\n",
    "\n",
    "    # Retrain on full 80% training data with best degree and test the model\n",
    "    model, test_error_rate = train_and_test_model(X_train, X_test, y_train, y_test, 'polynomial', best_degree, True)\n",
    "    test_error_rates[run] = test_error_rate\n",
    "    \n",
    "    # record the confusion matrix for the run\n",
    "    confusion_matrixs.append(model.confusion_matrix)\n",
    "\n",
    "# Calculate and print the mean and std of test error and best degree\n",
    "mean_test_error = test_error_rates.mean()\n",
    "std_test_error = test_error_rates.std()\n",
    "mean_best_degree = best_degrees.mean()\n",
    "std_best_degree = best_degrees.std()\n",
    "\n",
    "print(f\"Mean test error: {mean_test_error:.3f}±{std_test_error:.3f}\")\n",
    "print(f\"Mean best degree: {mean_best_degree:.3f}±{std_best_degree:.3f}\\n\")\n",
    "\n",
    "for i in range(num_runs):\n",
    "    print(f\"run: {i}, d*={best_degrees[i]}, test error rate={test_error_rates[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788ec13e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.016±0.069</td>\n",
       "      <td>0.265±0.328</td>\n",
       "      <td>0.286±0.243</td>\n",
       "      <td>0.050±0.120</td>\n",
       "      <td>0.322±0.254</td>\n",
       "      <td>0.270±0.327</td>\n",
       "      <td>0.033±0.099</td>\n",
       "      <td>0.099±0.152</td>\n",
       "      <td>0.031±0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.036±0.109</td>\n",
       "      <td>0.039±0.118</td>\n",
       "      <td>0.495±0.956</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.196±0.278</td>\n",
       "      <td>0.039±0.168</td>\n",
       "      <td>0.082±0.165</td>\n",
       "      <td>0.058±0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579±0.624</td>\n",
       "      <td>0.190±0.306</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.708±0.511</td>\n",
       "      <td>0.598±0.741</td>\n",
       "      <td>0.164±0.429</td>\n",
       "      <td>0.218±0.412</td>\n",
       "      <td>0.776±0.657</td>\n",
       "      <td>0.312±0.499</td>\n",
       "      <td>0.053±0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.171±0.315</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.922±0.725</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.153±0.325</td>\n",
       "      <td>2.249±1.029</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.391±0.508</td>\n",
       "      <td>0.805±0.819</td>\n",
       "      <td>0.154±0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148±0.324</td>\n",
       "      <td>0.707±0.596</td>\n",
       "      <td>0.563±0.581</td>\n",
       "      <td>0.091±0.216</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.186±0.350</td>\n",
       "      <td>0.655±0.498</td>\n",
       "      <td>0.289±0.427</td>\n",
       "      <td>0.117±0.235</td>\n",
       "      <td>0.836±0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.746±0.782</td>\n",
       "      <td>0.071±0.213</td>\n",
       "      <td>0.631±0.582</td>\n",
       "      <td>1.531±0.968</td>\n",
       "      <td>0.531±0.595</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.832±0.594</td>\n",
       "      <td>0.172±0.299</td>\n",
       "      <td>0.613±0.662</td>\n",
       "      <td>0.285±0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.780±0.714</td>\n",
       "      <td>0.191±0.292</td>\n",
       "      <td>0.125±0.251</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.592±0.622</td>\n",
       "      <td>0.554±0.502</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.030±0.129</td>\n",
       "      <td>0.390±0.587</td>\n",
       "      <td>0.026±0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.190±0.351</td>\n",
       "      <td>0.446±0.564</td>\n",
       "      <td>0.093±0.221</td>\n",
       "      <td>0.898±0.699</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.387±0.478</td>\n",
       "      <td>0.826±0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.814±0.754</td>\n",
       "      <td>0.569±0.620</td>\n",
       "      <td>0.870±0.832</td>\n",
       "      <td>1.708±0.980</td>\n",
       "      <td>0.629±0.669</td>\n",
       "      <td>1.224±0.669</td>\n",
       "      <td>0.327±0.420</td>\n",
       "      <td>0.182±0.316</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.464±0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.203±0.415</td>\n",
       "      <td>0.210±0.352</td>\n",
       "      <td>0.208±0.284</td>\n",
       "      <td>0.208±0.285</td>\n",
       "      <td>1.639±0.943</td>\n",
       "      <td>0.233±0.287</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>1.231±1.057</td>\n",
       "      <td>0.296±0.479</td>\n",
       "      <td>0.000±0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2            3            4  \\\n",
       "0  0.000±0.000  0.016±0.069  0.265±0.328  0.286±0.243  0.050±0.120   \n",
       "1  0.000±0.000  0.000±0.000  0.036±0.109  0.039±0.118  0.495±0.956   \n",
       "2  0.579±0.624  0.190±0.306  0.000±0.000  0.708±0.511  0.598±0.741   \n",
       "3  0.171±0.315  0.000±0.000  0.922±0.725  0.000±0.000  0.153±0.325   \n",
       "4  0.148±0.324  0.707±0.596  0.563±0.581  0.091±0.216  0.000±0.000   \n",
       "5  0.746±0.782  0.071±0.213  0.631±0.582  1.531±0.968  0.531±0.595   \n",
       "6  0.780±0.714  0.191±0.292  0.125±0.251  0.000±0.000  0.592±0.622   \n",
       "7  0.000±0.000  0.190±0.351  0.446±0.564  0.093±0.221  0.898±0.699   \n",
       "8  0.814±0.754  0.569±0.620  0.870±0.832  1.708±0.980  0.629±0.669   \n",
       "9  0.203±0.415  0.210±0.352  0.208±0.284  0.208±0.285  1.639±0.943   \n",
       "\n",
       "             5            6            7            8            9  \n",
       "0  0.322±0.254  0.270±0.327  0.033±0.099  0.099±0.152  0.031±0.094  \n",
       "1  0.000±0.000  0.196±0.278  0.039±0.168  0.082±0.165  0.058±0.183  \n",
       "2  0.164±0.429  0.218±0.412  0.776±0.657  0.312±0.499  0.053±0.158  \n",
       "3  2.249±1.029  0.000±0.000  0.391±0.508  0.805±0.819  0.154±0.267  \n",
       "4  0.186±0.350  0.655±0.498  0.289±0.427  0.117±0.235  0.836±0.778  \n",
       "5  0.000±0.000  0.832±0.594  0.172±0.299  0.613±0.662  0.285±0.412  \n",
       "6  0.554±0.502  0.000±0.000  0.030±0.129  0.390±0.587  0.026±0.114  \n",
       "7  0.000±0.000  0.000±0.000  0.000±0.000  0.387±0.478  0.826±0.608  \n",
       "8  1.224±0.669  0.327±0.420  0.182±0.316  0.000±0.000  0.464±0.597  \n",
       "9  0.233±0.287  0.000±0.000  1.231±1.057  0.296±0.479  0.000±0.000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise empty matrix for averages\n",
    "averaged_cm = [[''] * 10 for _ in range(10)]\n",
    "\n",
    "# Calculate the mean and std of each cell in the confusion matrices\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        errors = np.array([cm[i, j] for cm in confusion_matrixs])\n",
    "        mean = np.mean(errors) * 100\n",
    "        std = np.std(errors) * 100\n",
    "        averaged_cm[i][j] = f\"{np.mean(errors) * 100:.3f}±{np.std(errors) * 100:.3f}\"\n",
    "        \n",
    "# Convert the averaged confusion matrix to a DataFrame for better visualisation\n",
    "pd.DataFrame(data=averaged_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35db83b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 100/100 [48:03<00:00, 28.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# Part3 Q4\n",
    "\n",
    "# Initialise the the dictionary to record misclassification for each image\n",
    "misclassification_counts = {i: {} for i in range(len(labels))}\n",
    "num_runs = 100\n",
    "\n",
    "for run in tqdm(range(num_runs)):\n",
    "    X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(images, labels, range(len(labels)), test_size=0.2)\n",
    "    \n",
    "    # Determine the best degree of the run using cross-validation\n",
    "    best_degree = cross_validate_for_best_parameter(X_train, y_train, 'polynomial', degree_list)\n",
    "\n",
    "    # Retrain on full 80% training data with best degree and test\n",
    "    model, test_error_rate = train_and_test_model(X_train, X_test, y_train, y_test, 'polynomial', best_degree, True)\n",
    " \n",
    "    # Iterate over each instance in X_test to predict and compare with y_test\n",
    "    for i in range(len(y_test)):\n",
    "        K_i = model.K_test[i]\n",
    "        y_pred = model.predict(K_i)\n",
    "        true_label = int(y_test[i])\n",
    "        if y_pred != true_label:\n",
    "            # Increment the error count for the original index of the test image\n",
    "            original_index = idx_test[i]\n",
    "            if y_pred not in misclassification_counts[original_index]:\n",
    "                misclassification_counts[original_index][y_pred] = 0\n",
    "            misclassification_counts[original_index][y_pred] += 1\n",
    "\n",
    "# Find the indices of the five images with the most errors\n",
    "error_counts = {idx: sum(misclassifications.values()) for idx, misclassifications in misclassification_counts.items()}\n",
    "hardest_to_predict_indices = sorted(error_counts, key=error_counts.get, reverse=True)[:5]\n",
    "hardest_to_predict_info = {idx: misclassification_counts[idx] for idx in hardest_to_predict_indices}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13b3c341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the images of top five misclassified digits\n",
    "plt.figure(figsize = (16,8))\n",
    "for i,j in enumerate(hardest_to_predict_indices):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(images[j,:].reshape(16,16), cmap='gray')\n",
    "    plt.title(f'True label = {int(labels[j])}', fontsize=22)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"hardest_to_predict.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f7f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2663: {5: 27},\n",
       " 3100: {4: 26},\n",
       " 7489: {0: 23, 5: 2, 2: 1},\n",
       " 7807: {3: 24, 5: 2},\n",
       " 2343: {1: 20, 8: 2, 3: 3}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hardest_to_predict_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e428bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.0001 \n",
      "    Mean train error rate: 23.141%±0.248%, Mean test error rate: 18.468%±7.800%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.001 \n",
      "    Mean train error rate: 10.903%±0.183%, Mean test error rate: 9.164%±3.159%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.01 \n",
      "    Mean train error rate: 2.536%±0.048%, Mean test error rate: 3.519%±0.447%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.1 \n",
      "    Mean train error rate: 2.242%±0.036%, Mean test error rate: 5.000%±0.465%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 1 \n",
      "    Mean train error rate: 2.558%±0.051%, Mean test error rate: 5.887%±0.400%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:20<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 10 \n",
      "    Mean train error rate: 5.703%±0.056%, Mean test error rate: 19.704%±0.872%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:20<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 100 \n",
      "    Mean train error rate: 14.622%±0.060%, Mean test error rate: 71.602%±1.121%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 3 Q5.1\n",
    "\n",
    "# First experiment to determine the reasonable c list\n",
    "c_list = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "num_c = len(c_list)\n",
    "num_runs = 20\n",
    "\n",
    "train_error_rates, test_error_rates = np.zeros(num_c), np.zeros(num_c)\n",
    "train_stds, test_stds = np.zeros(num_c), np.zeros(num_c)\n",
    "\n",
    "for c in c_list:\n",
    "    c_train_errors, c_test_errors = np.zeros(num_runs), np.zeros(num_runs)\n",
    "    \n",
    "    for run in tqdm(range(num_runs)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "        \n",
    "        train_error_rate, test_error_rate = train_and_test_model(X_train, X_test, y_train, y_test, 'gaussian', c)\n",
    "        c_train_errors[run], c_test_errors[run] = train_error_rate, test_error_rate\n",
    "\n",
    "    # Print results for current c\n",
    "    print(f\"c: {c} \\n    Mean train error rate: {c_train_errors.mean():.3f}%±\\\n",
    "{c_train_errors.std():.3f}%, Mean test error rate: \\\n",
    "{c_test_errors.mean():.3f}%±{c_test_errors.std():.3f}%\")  \n",
    "    \n",
    "    # Store the mean and std of errors for each c\n",
    "    train_error_rates[degree - 1] = c_train_errors.mean()\n",
    "    train_stds[degree - 1] = c_train_errors.std()\n",
    "    test_error_rates[degree - 1] = c_test_errors.mean()\n",
    "    test_stds[degree - 1] = c_test_errors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a5b4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.001 \n",
      "    Mean train error rate: 10.957%±0.179%, Mean test error rate: 8.384%±2.425%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.005 \n",
      "    Mean train error rate: 4.065%±0.093%, Mean test error rate: 4.250%±0.644%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.01 \n",
      "    Mean train error rate: 2.556%±0.047%, Mean test error rate: 3.164%±0.644%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.05 \n",
      "    Mean train error rate: 2.025%±0.034%, Mean test error rate: 3.887%±0.447%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.1 \n",
      "    Mean train error rate: 2.248%±0.061%, Mean test error rate: 5.231%±0.338%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:22<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.5 \n",
      "    Mean train error rate: 2.513%±0.060%, Mean test error rate: 5.989%±0.601%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 1 \n",
      "    Mean train error rate: 2.552%±0.068%, Mean test error rate: 6.185%±0.483%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Second experiment to narrow down the range of the c\n",
    "c_list = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]\n",
    "num_c = len(c_list)\n",
    "num_runs = 20\n",
    "\n",
    "# Initialise arrays to store error rates and stds\n",
    "train_error_rates, test_error_rates = np.zeros(num_c), np.zeros(num_c)\n",
    "train_stds, test_stds = np.zeros(num_c), np.zeros(num_c)\n",
    "\n",
    "for c in c_list:\n",
    "    c_train_errors, c_test_errors = np.zeros(num_runs), np.zeros(num_runs)\n",
    "    \n",
    "    for run in tqdm(range(num_runs)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "        \n",
    "        train_error_rate, test_error_rate = train_and_test_model(X_train, X_test, y_train, y_test, 'gaussian', c)\n",
    "        c_train_errors[run], c_test_errors[run] = train_error_rate, test_error_rate\n",
    "\n",
    "    # Print results for current c\n",
    "    print(f\"c: {c} \\n    Mean train error rate: {c_train_errors.mean():.3f}%±\\\n",
    "{c_train_errors.std():.3f}%, Mean test error rate: \\\n",
    "{c_test_errors.mean():.3f}%±{c_test_errors.std():.3f}%\")  \n",
    "        \n",
    "    # Store the mean and std of errors for each c\n",
    "    train_error_rates[degree - 1] = c_train_errors.mean()\n",
    "    test_error_rates[degree - 1] = c_test_errors.mean()\n",
    "    train_stds[degree - 1] = c_train_errors.std()\n",
    "    test_stds[degree - 1] = c_test_errors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30dd85c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.009 \n",
      "    Mean train error rate: 2.697%±0.055%, Mean test error rate: 3.691%±0.395%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.01 \n",
      "    Mean train error rate: 2.563%±0.060%, Mean test error rate: 3.419%±0.514%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.013 \n",
      "    Mean train error rate: 2.264%±0.049%, Mean test error rate: 3.180%±0.355%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.015 \n",
      "    Mean train error rate: 2.174%±0.037%, Mean test error rate: 3.040%±0.414%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.018 \n",
      "    Mean train error rate: 2.037%±0.043%, Mean test error rate: 3.070%±0.438%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:22<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.02 \n",
      "    Mean train error rate: 2.016%±0.045%, Mean test error rate: 3.266%±0.350%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:21<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: 0.03 \n",
      "    Mean train error rate: 1.931%±0.033%, Mean test error rate: 3.460%±0.472%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Record the basic result for refined c list\n",
    "c_list = [0.009, 0.01, 0.013, 0.015, 0.018, 0.02, 0.03]\n",
    "num_c = len(c_list)\n",
    "num_runs = 20\n",
    "\n",
    "# Initialise arrays to store error rates and stds\n",
    "train_error_rates, test_error_rates = np.zeros(num_c), np.zeros(num_c)\n",
    "train_stds, test_stds = np.zeros(num_c), np.zeros(num_c)\n",
    "\n",
    "for c in c_list:\n",
    "    c_train_errors, c_test_errors = np.zeros(num_runs), np.zeros(num_runs)\n",
    "    \n",
    "    for run in tqdm(range(num_runs)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "        \n",
    "        train_error_rate, test_error_rate = train_and_test_model(X_train, X_test, y_train, y_test, 'gaussian', c)\n",
    "        c_train_errors[run], c_test_errors[run] = train_error_rate, test_error_rate\n",
    "\n",
    "    # Print results for current c\n",
    "    print(f\"c: {c} \\n    Mean train error rate: {c_train_errors.mean():.3f}%±\\\n",
    "{c_train_errors.std():.3f}%, Mean test error rate: \\\n",
    "{c_test_errors.mean():.3f}%±{c_test_errors.std():.3f}%\")   \n",
    "    \n",
    "    # Store the mean and std of errors for each c\n",
    "    train_error_rates[degree - 1] = c_train_errors.mean()\n",
    "    test_error_rates[degree - 1] = c_test_errors.mean()\n",
    "    train_stds[degree - 1] = c_train_errors.std()\n",
    "    test_stds[degree - 1] = c_test_errors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "013b5c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [09:23<00:00, 28.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test error: 3.062 ± 0.350\n",
      "Mean best c: 0.0168 ± 0.0028\n",
      "run: 0, c*=0.018, test error rate=3.118\n",
      "run: 1, c*=0.018, test error rate=3.387\n",
      "run: 2, c*=0.020, test error rate=3.495\n",
      "run: 3, c*=0.018, test error rate=3.602\n",
      "run: 4, c*=0.015, test error rate=3.172\n",
      "run: 5, c*=0.020, test error rate=3.011\n",
      "run: 6, c*=0.013, test error rate=3.226\n",
      "run: 7, c*=0.015, test error rate=3.441\n",
      "run: 8, c*=0.013, test error rate=3.387\n",
      "run: 9, c*=0.013, test error rate=2.849\n",
      "run: 10, c*=0.020, test error rate=3.226\n",
      "run: 11, c*=0.013, test error rate=3.172\n",
      "run: 12, c*=0.020, test error rate=3.118\n",
      "run: 13, c*=0.015, test error rate=2.312\n",
      "run: 14, c*=0.020, test error rate=2.634\n",
      "run: 15, c*=0.020, test error rate=2.849\n",
      "run: 16, c*=0.013, test error rate=3.011\n",
      "run: 17, c*=0.018, test error rate=2.634\n",
      "run: 18, c*=0.015, test error rate=2.366\n",
      "run: 19, c*=0.018, test error rate=3.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Part3 Q5.2\n",
    "c_list = [0.009, 0.01, 0.013, 0.015, 0.018, 0.02, 0.03]\n",
    "num_runs = 20\n",
    "\n",
    "best_cs = np.zeros(num_runs)\n",
    "test_error_rates = np.zeros(num_runs)\n",
    "\n",
    "for run in tqdm(range(num_runs)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "\n",
    "    # Determine and record the best c of the run\n",
    "    best_c = cross_validate_for_best_parameter(X_train, y_train, 'gaussian', c_list)\n",
    "    best_cs[run] = best_c\n",
    "\n",
    "    # Retrain on full 80% training data with best c and test\n",
    "    _, test_error_rate = train_and_test_model(X_train, X_test, y_train, y_test, 'gaussian', best_c)\n",
    "    test_error_rates[run] = test_error_rate\n",
    "\n",
    "mean_test_error = test_error_rates.mean()\n",
    "std_test_error = test_error_rates.std()\n",
    "mean_best_cs = best_cs.mean()\n",
    "std_best_cs = best_cs.std()\n",
    "\n",
    "print(f\"Mean test error: {mean_test_error:.3f} ± {std_test_error:.3f}\")\n",
    "print(f\"Mean best c: {mean_best_cs:.4f} ± {std_best_cs:.4f}\")\n",
    "\n",
    "for i in range(num_runs):\n",
    "    print(f\"run: {i}, c*={best_cs[i]:.3f}, test error rate={test_error_rates[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba15d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
