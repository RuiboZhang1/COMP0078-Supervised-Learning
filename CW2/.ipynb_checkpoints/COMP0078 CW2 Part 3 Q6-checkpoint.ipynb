{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac6cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a71cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for the coursework\n",
    "np.random.seed(124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5527a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the polynomial kernel\n",
    "def polynomial_kernel(p, q, d):\n",
    "    return (p @ q.T) ** d\n",
    "\n",
    "# Define the gaussian kernel\n",
    "def gaussian_kernel(p, q, c):\n",
    "    return np.exp(-c * euclidean_distances(p, q) ** 2)\n",
    "\n",
    "# Get the list of combinations given the list of classes\n",
    "def get_combinations(classes):\n",
    "    return list(combinations(classes, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03caf77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "with open('./dataset/zipcombo.dat', 'r') as file:\n",
    "    for line in file:\n",
    "        values = list(map(float, line.strip().split()))\n",
    "        labels.append(values[0])\n",
    "        images.append(np.array(values[1:]))\n",
    "    \n",
    "labels = np.array(labels)\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32df9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OvOKernelPerceptron:\n",
    "    def __init__(self, epochs, X_train, X_test, y_train, y_test, kernel_type, kernel_param):\n",
    "        self.epochs = epochs  # Number of times the training data will be iterated over\n",
    "        self.X_train = X_train \n",
    "        self.X_test = X_test  \n",
    "        self.y_train = y_train  \n",
    "        self.y_test = y_test  \n",
    "        \n",
    "        # Calculate the number of unique classes in the dataset\n",
    "        self.num_classes = len(np.unique(np.append(y_train, y_test)))\n",
    "        self.train_size = X_train.shape[0]  # Number of training examples\n",
    "        self.test_size = X_test.shape[0]  # Number of testing examples\n",
    "        self.classifiers = get_combinations(np.arange(0, 10)) # Get all combinations of classifiers for OvO\n",
    "        self.num_classifiers = len(self.classifiers) # # Number of classifiers needed for OvO \n",
    "        \n",
    "        # Initialise the alpha coefficients for each classifier and training example\n",
    "        self.alpha = np.zeros((self.num_classifiers, self.train_size))\n",
    "\n",
    "        # Initialise the kernel based on the specified type and parameter\n",
    "        if kernel_type == \"polynomial\":\n",
    "            self.K_train = polynomial_kernel(self.X_train, self.X_train, kernel_param)\n",
    "            self.K_test = polynomial_kernel(self.X_test, self.X_train, kernel_param)\n",
    "        elif kernel_type == \"gaussian\":\n",
    "            self.K_train = gaussian_kernel(self.X_train, self.X_train, kernel_param)\n",
    "            self.K_test = gaussian_kernel(self.X_test, self.X_train, kernel_param)\n",
    "        \n",
    "    def predict(self, K):\n",
    "        # Make a prediction for the i-th example\n",
    "        votes = self.alpha @ K # Get the votes for all classifiers\n",
    "        class_votes = np.zeros(self.num_classes) # Initialise the array to record the vote for each class\n",
    "        \n",
    "        for j, vote in enumerate(votes):\n",
    "            combo = self.classifiers[j]\n",
    "            \n",
    "            # If vote > 0, then vote for the first class in the combination, else vote for the second class\n",
    "            voted_class = combo[0] if vote > 0 else combo[1] \n",
    "            class_votes[voted_class] += 1\n",
    "        \n",
    "        # Return the class with the most votes\n",
    "        return np.argmax(class_votes) \n",
    "\n",
    "    def fit(self):\n",
    "        # Train the perceptron model\n",
    "        errors = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            for t in range(self.train_size):\n",
    "                K_t = self.K_train[t]\n",
    "                y_t = int(self.y_train[t])\n",
    "                y_pred = self.predict(K_t)\n",
    "                if y_pred != y_t:\n",
    "                    # Update alpha coefficients for misclassified examples\n",
    "                    for j, combo in enumerate(self.classifiers):\n",
    "                        if y_t in combo:\n",
    "                            update = 1 if combo[0] == y_t else -1\n",
    "                            self.alpha[j, t] += update\n",
    "                    errors += 1\n",
    "        # Return the percentage error over all epochs\n",
    "        return errors / (self.epochs * self.train_size) * 100\n",
    "\n",
    "    def test(self):\n",
    "        # Evaluate the model on the test dataset\n",
    "        errors = 0\n",
    "        for i in range(self.test_size):\n",
    "            K_i = self.K_test[i]\n",
    "            y_i = int(self.y_test[i])\n",
    "            y_pred = self.predict(K_i)\n",
    "            if y_i != y_pred:\n",
    "                errors += 1\n",
    "                \n",
    "        return errors / self.test_size * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1380bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(X_train, X_test, y_train, y_test, kernel_type, kernel_param, return_model=False):\n",
    "    # Initialize the perceptron model with specified kernel and kernel parameter\n",
    "    ovo_kernel_perceptron = OvOKernelPerceptron(5, X_train, X_test, y_train, y_test, kernel_type, kernel_param)\n",
    "    \n",
    "    # Train model and record training error rate\n",
    "    train_error_rate = ovo_kernel_perceptron.fit()\n",
    "    \n",
    "    # Test model and record testing error rate\n",
    "    test_error_rate = ovo_kernel_perceptron.test()\n",
    "    \n",
    "    if return_model:\n",
    "        return ovo_kernel_perceptron, test_error_rate\n",
    "    else:\n",
    "        return train_error_rate, test_error_rate\n",
    "\n",
    "def cross_validate_for_best_parameter(X_train, y_train, kernel_type, param_list, n_splits=5):\n",
    "    # Initialize KFold for cross-validation\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    val_error_rates = np.zeros(len(param_list))\n",
    "\n",
    "    # Loop over each fold in cross-validation\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        # Create training and validation sets for this fold\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        # Evaluate each parameter using cross-validation\n",
    "        for i, param in enumerate(param_list):\n",
    "            train_error, val_error = train_and_test_model(X_train_fold, X_val_fold, y_train_fold, y_val_fold, kernel_type, param)\n",
    "            val_error_rates[i] += val_error\n",
    "\n",
    "    # Determine the best parameter with minimum validation error rate\n",
    "    best_param = param_list[np.argmin(val_error_rates)]\n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36951adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:52<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 1 \n",
      "    Mean train error rate: 10.589%±0.237%, Mean test error rate: 9.941%±0.618%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [01:00<00:00,  3.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 2 \n",
      "    Mean train error rate: 6.505%±0.222%, Mean test error rate: 6.825%±0.603%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [01:08<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 3 \n",
      "    Mean train error rate: 4.168%±0.135%, Mean test error rate: 5.785%±0.562%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [01:30<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 4 \n",
      "    Mean train error rate: 3.157%±0.132%, Mean test error rate: 5.272%±0.563%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [01:05<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 5 \n",
      "    Mean train error rate: 2.605%±0.145%, Mean test error rate: 4.960%±0.525%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [00:57<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 6 \n",
      "    Mean train error rate: 2.336%±0.113%, Mean test error rate: 4.772%±0.443%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [01:10<00:00,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 7 \n",
      "    Mean train error rate: 2.190%±0.105%, Mean test error rate: 4.718%±0.495%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 3 Q6.1\n",
    "\n",
    "# Initialise parameters\n",
    "degree_list = np.arange(1, 8)\n",
    "num_runs = 20\n",
    "num_degrees = len(degree_list)\n",
    "\n",
    "# Initialise arrays to store error rates and stds\n",
    "train_error_rates, test_error_rates = np.zeros(num_degrees), np.zeros(num_degrees)\n",
    "train_stds, test_stds = np.zeros(num_degrees), np.zeros(num_degrees)\n",
    "\n",
    "for degree in degree_list:\n",
    "    degree_train_errors, degree_test_errors = np.zeros(num_runs), np.zeros(num_runs)\n",
    "    \n",
    "    for run in tqdm(range(num_runs)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "        \n",
    "        train_error_rate, test_error_rate = train_and_test_model(X_train, X_test, y_train, y_test, 'polynomial', degree)\n",
    "        degree_train_errors[run], degree_test_errors[run] = train_error_rate, test_error_rate\n",
    "\n",
    "    # Print results for current degree\n",
    "    print(f\"Degree: {degree} \\n    Mean train error rate: {degree_train_errors.mean():.3f}%±\\\n",
    "{degree_train_errors.std():.3f}%, Mean test error rate: \\\n",
    "{degree_test_errors.mean():.3f}%±{degree_test_errors.std():.3f}%\")        \n",
    "        \n",
    "    # Store the mean and std of errors for each degree\n",
    "    train_error_rates[degree - 1] = degree_train_errors.mean()\n",
    "    test_error_rates[degree - 1] = degree_test_errors.mean()\n",
    "    train_stds[degree - 1] = degree_train_errors.std()\n",
    "    test_stds[degree - 1] = degree_test_errors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "914a28f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 20/20 [22:30<00:00, 67.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test error: 4.761±0.643\n",
      "Mean best degree: 6.550±0.589\n",
      "\n",
      "run: 0, d*=5.0, test error rate=5.269\n",
      "run: 1, d*=7.0, test error rate=4.516\n",
      "run: 2, d*=6.0, test error rate=4.462\n",
      "run: 3, d*=6.0, test error rate=4.194\n",
      "run: 4, d*=6.0, test error rate=4.462\n",
      "run: 5, d*=6.0, test error rate=4.785\n",
      "run: 6, d*=7.0, test error rate=5.484\n",
      "run: 7, d*=7.0, test error rate=4.301\n",
      "run: 8, d*=7.0, test error rate=3.871\n",
      "run: 9, d*=6.0, test error rate=6.129\n",
      "run: 10, d*=7.0, test error rate=5.430\n",
      "run: 11, d*=7.0, test error rate=4.355\n",
      "run: 12, d*=7.0, test error rate=6.129\n",
      "run: 13, d*=7.0, test error rate=4.839\n",
      "run: 14, d*=7.0, test error rate=4.892\n",
      "run: 15, d*=7.0, test error rate=4.624\n",
      "run: 16, d*=6.0, test error rate=4.409\n",
      "run: 17, d*=7.0, test error rate=3.710\n",
      "run: 18, d*=7.0, test error rate=5.054\n",
      "run: 19, d*=6.0, test error rate=4.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Part3 Q6.2\n",
    "\n",
    "# Initialise arrays for storing results\n",
    "num_runs = 20\n",
    "best_degrees = np.zeros(num_runs)\n",
    "test_error_rates = np.zeros(num_runs)\n",
    "\n",
    "\n",
    "for run in tqdm(range(num_runs)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "\n",
    "    # Determine and record the best degree of the run\n",
    "    best_degree = cross_validate_for_best_parameter(X_train, y_train, 'polynomial', degree_list)\n",
    "    best_degrees[run] = best_degree\n",
    "\n",
    "    # Retrain on full 80% training data with best degree and test\n",
    "    train_error_rate, test_error_rate = train_and_test_model(X_train, X_test, y_train, y_test, 'polynomial', best_degree)\n",
    "    test_error_rates[run] = test_error_rate\n",
    "    \n",
    "\n",
    "# Calculate and print the mean and std of test error and best degree\n",
    "mean_test_error = test_error_rates.mean()\n",
    "std_test_error = test_error_rates.std()\n",
    "mean_best_degree = best_degrees.mean()\n",
    "std_best_degree = best_degrees.std()\n",
    "\n",
    "print(f\"Mean test error: {mean_test_error:.3f}±{std_test_error:.3f}\")\n",
    "print(f\"Mean best degree: {mean_best_degree:.3f}±{std_best_degree:.3f}\\n\")\n",
    "\n",
    "for i in range(num_runs):\n",
    "    print(f\"run: {i}, d*={best_degrees[i]}, test error rate={test_error_rates[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabb378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
